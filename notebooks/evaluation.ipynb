import pandas as pd
from src.core.rag_engine import EliteRAGSystem

# Elite test cases
TEST_CASES = [
    {
        "question": "What are the top 3 issues with BNPL late fees?",
        "expected_answer": "1) Unclear due dates 2) System glitches marking payments late 3) Excessive penalty amounts"
    },
    # Add 5-10 more cases
]

def run_elite_evaluation():
    rag = EliteRAGSystem(vector_store)
    results = rag.evaluate(TEST_CASES)
    
    eval_df = pd.DataFrame([{
        "Question": r["question"],
        "Generated Answer": r["generated"],
        "Retrieved Sources": "\n".join([f"{s['product']} ({s['date']})" for s in r["sources"]]),
        "Context Relevance": len([1 for s in r["sources"] if s["similarity_score"] > 0.7]),
        "Answer Quality": input(f"Rate answer (1-5) for: {r['question']}\n{r['generated']}\n"),
        "Innovation Score": input("Rate creativity (1-5): ")
    } for r in results])
    
    display(eval_df.style.background_gradient(cmap="RdYlGn"))
    return eval_df